{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"team_8_report.ipynb","provenance":[{"file_id":"1zZtqn_1I7npreQg8-9_bGeLbkLsCn0R2","timestamp":1623862184439},{"file_id":"1wV5JUeILnhP_Ra474QsuDn__mXC_r8hC","timestamp":1623859823886},{"file_id":"1KQS0YM8m-sr9GtVyWCVf1tJ98E8YEpue","timestamp":1623467196476},{"file_id":"1DTfVCmqVe1Tjt6JDFk4wGYRGYzPkmdXo","timestamp":1623425633595},{"file_id":"1l52RhUVfqJLNW1Sp_KUGH3oNFbhu0BRj","timestamp":1623398194229}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AL-8fZ6MeHnk"},"source":["# Facial expression classification based on VGG16 model"]},{"cell_type":"code","metadata":{"id":"H2i30gIHi3yP"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SmRgVRLufpUS"},"source":["## i. Import packages"]},{"cell_type":"code","metadata":{"id":"6X28qeliwT1g"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import csv\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.activations import swish\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPool2D, AveragePooling2D\n","from keras.layers import Dense, Activation, Dropout, Flatten\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.metrics import categorical_accuracy\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import *\n","from keras.layers.normalization import BatchNormalization\n","from keras import backend as K\n","from keras import regularizers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fhnZ4dZnfKfn"},"source":["## ii. Mount the Google Drive to Google Colab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNyII9DbeFaY","executionInfo":{"status":"ok","timestamp":1623815423699,"user_tz":-480,"elapsed":18931,"user":{"displayName":"盧怡帆","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhH1awS7-EaSw_GMexauq3kaoXt_XZ5XIs0F3OI1w=s64","userId":"01237958967479696027"}},"outputId":"3202a60a-8565-4df7-a64b-d4b405ceb213"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/ML_project/data/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1c2j1ue8z_O6YR92z3E0-7_9xM6v2kjXx/ML_project/data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JV3jebw3hFsg"},"source":["## iii. Create the folders named \"model\" and \"result\""]},{"cell_type":"code","metadata":{"id":"NtVl_aLDvD_2"},"source":["folder_model = '/content/drive/MyDrive/ML_project/model'\n","if not os.path.exists(folder_model):\n","    os.makedirs(folder_model)\n","\n","folder_result = '/content/drive/MyDrive/ML_project/result'\n","if not os.path.exists(folder_result):\n","    os.makedirs(folder_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RtNqXkHzvHpn"},"source":["## iv. Data pre-processing"]},{"cell_type":"code","metadata":{"id":"XMVTFyCWxLSN"},"source":["def getData(filname):\n","    Y = []\n","    X = []\n","    first = True\n","    for line in open(filname):\n","        if first:\n","            first = False\n","        else:\n","            row = line.split(',')\n","            Y.append(int(row[0]))\n","            X.append([int(p) for p in row[1].split()])\n","    X, Y = np.array(X) / 255.0, np.array(Y)\n","    return X, Y\n","\n","# Training data\n","filname = '/content/drive/MyDrive/ML_project/data/train.csv'\n","X, Y = getData(filname)\n","num_class = len(set(Y))\n","N, D = X.shape\n","X = X.reshape(N, 48, 48, 1)\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)    # split the training data\n","y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n","y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)\n","\n","# Test data\n","fileTest = '/content/drive/MyDrive/ML_project/data/test.csv'\n","X_, Y_ = getData(fileTest)\n","N_, D_ = X_.shape\n","X_ = X_.reshape(N_, 48, 48, 1)\n","\n","# Data augmentation\n","datagen = ImageDataGenerator(\n","        rotation_range=15,\n","        width_shift_range=0.2,\n","        height_shift_range=0.2,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        fill_mode='nearest')\n","datagen.fit(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GvSVrAvHl3tZ"},"source":["## v. Model architecture based on VGG16"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BTg8Vufl1_w","executionInfo":{"status":"ok","timestamp":1623815528760,"user_tz":-480,"elapsed":5951,"user":{"displayName":"盧怡帆","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhH1awS7-EaSw_GMexauq3kaoXt_XZ5XIs0F3OI1w=s64","userId":"01237958967479696027"}},"outputId":"e76c431d-dcb7-4865-9553-9da532425b1d"},"source":["def cnn_model():\n","    model = Sequential()\n","\n","    # Block 1\n","    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation=swish, input_shape=(48, 48, 1)))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(64,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # Block 2\n","    model.add(Conv2D(128,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(128,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.25))\n","    \n","    # Block 3\n","    model.add(Conv2D(256,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(256,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(256,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # Block 4\n","    model.add(Conv2D(512,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(512,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(512,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # Block 5\n","    model.add(Conv2D(512,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(512,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(512,(3,3), padding='same', activation=swish))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # FC layers\n","    model.add(Flatten())\n","    model.add(Dense(256, activation = swish))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.25))\n","    model.add(Dense(512, activation = swish))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.25))\n","    model.add(Dense(7, activation='softmax', kernel_regularizer=regularizers.l2(1e-4)))\n","\n","    # config the model with losses and metrics\n","    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n","    \n","    return model\n","\n","# Show the architecture\n","model = cnn_model()\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 48, 48, 64)        640       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 48, 48, 64)        256       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 48, 48, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 12, 12, 256)       590080    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 12, 12, 256)       1024      \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 12, 12, 256)       1024      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 256)         0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 6, 6, 512)         1180160   \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 6, 6, 512)         2048      \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 6, 6, 512)         2048      \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 6, 6, 512)         2048      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 3, 3, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 3, 3, 512)         2048      \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 3, 3, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 3, 3, 512)         2048      \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 3, 3, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 3, 3, 512)         2048      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               131328    \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               131584    \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 512)               2048      \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 15,000,007\n","Trainable params: 14,990,023\n","Non-trainable params: 9,984\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"soo-YwpGl7op"},"source":["## vi. Train the model and save it as model_team8.h5 file"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LVTTjmvaxxyO","executionInfo":{"status":"ok","timestamp":1623827389374,"user_tz":-480,"elapsed":11838744,"user":{"displayName":"盧怡帆","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhH1awS7-EaSw_GMexauq3kaoXt_XZ5XIs0F3OI1w=s64","userId":"01237958967479696027"}},"outputId":"adbe85d6-2fec-449c-b4cb-7f252f87c65b"},"source":["%cd /content/drive/MyDrive/ML_project/model/\n","path_model='model_team8.h5'    # save model at this location after each epoch\n","K.clear_session()    # destroys the current graph and builds a new one\n","model=cnn_model()    # create the model\n","K.set_value(model.optimizer.lr,1e-3)    # set the learning rate\n","h = model.fit_generator(datagen.flow(X_train, y_train, batch_size=64), \n","                    steps_per_epoch=X_train.shape[0]/64, \n","                    epochs=320,\n","                    validation_data=(X_test,y_test),\n","                    validation_steps=X_test.shape[0]/64,\n","                    shuffle=True,\n","                    callbacks=[\n","                        ModelCheckpoint(filepath=path_model),\n","                    ]\n","                    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/320\n","406/406 [==============================] - 85s 86ms/step - loss: 2.2825 - accuracy: 0.1869 - val_loss: 1.9233 - val_accuracy: 0.1582\n","Epoch 2/320\n","406/406 [==============================] - 33s 81ms/step - loss: 1.9114 - accuracy: 0.2138 - val_loss: 1.8315 - val_accuracy: 0.2122\n","Epoch 3/320\n","406/406 [==============================] - 33s 82ms/step - loss: 1.8528 - accuracy: 0.2395 - val_loss: 1.8682 - val_accuracy: 0.1648\n","Epoch 4/320\n","406/406 [==============================] - 34s 83ms/step - loss: 1.8158 - accuracy: 0.2572 - val_loss: 3.7821 - val_accuracy: 0.1720\n","Epoch 5/320\n","406/406 [==============================] - 34s 83ms/step - loss: 1.7179 - accuracy: 0.3167 - val_loss: 1.5337 - val_accuracy: 0.4071\n","Epoch 6/320\n","406/406 [==============================] - 34s 83ms/step - loss: 1.5226 - accuracy: 0.4109 - val_loss: 1.4478 - val_accuracy: 0.4451\n","Epoch 7/320\n","406/406 [==============================] - 34s 84ms/step - loss: 1.4219 - accuracy: 0.4550 - val_loss: 1.3373 - val_accuracy: 0.4808\n","Epoch 8/320\n","406/406 [==============================] - 35s 85ms/step - loss: 1.3643 - accuracy: 0.4820 - val_loss: 1.2224 - val_accuracy: 0.5344\n","Epoch 9/320\n","406/406 [==============================] - 34s 84ms/step - loss: 1.2905 - accuracy: 0.5118 - val_loss: 1.2487 - val_accuracy: 0.5151\n","Epoch 10/320\n","406/406 [==============================] - 34s 85ms/step - loss: 1.2542 - accuracy: 0.5296 - val_loss: 1.2881 - val_accuracy: 0.5303\n","Epoch 11/320\n","406/406 [==============================] - 35s 85ms/step - loss: 1.2191 - accuracy: 0.5428 - val_loss: 1.2827 - val_accuracy: 0.5168\n","Epoch 12/320\n","406/406 [==============================] - 35s 85ms/step - loss: 1.1846 - accuracy: 0.5580 - val_loss: 1.1422 - val_accuracy: 0.5701\n","Epoch 13/320\n","406/406 [==============================] - 34s 85ms/step - loss: 1.1599 - accuracy: 0.5690 - val_loss: 1.1580 - val_accuracy: 0.5694\n","Epoch 14/320\n","406/406 [==============================] - 34s 85ms/step - loss: 1.1247 - accuracy: 0.5818 - val_loss: 1.1919 - val_accuracy: 0.5587\n","Epoch 15/320\n","406/406 [==============================] - 35s 85ms/step - loss: 1.1251 - accuracy: 0.5819 - val_loss: 1.0908 - val_accuracy: 0.5881\n","Epoch 16/320\n","406/406 [==============================] - 34s 85ms/step - loss: 1.1044 - accuracy: 0.5909 - val_loss: 1.0838 - val_accuracy: 0.5905\n","Epoch 17/320\n","406/406 [==============================] - 34s 85ms/step - loss: 1.0882 - accuracy: 0.5962 - val_loss: 1.1354 - val_accuracy: 0.5839\n","Epoch 18/320\n","406/406 [==============================] - 34s 84ms/step - loss: 1.0559 - accuracy: 0.6035 - val_loss: 1.0683 - val_accuracy: 0.6061\n","Epoch 19/320\n","406/406 [==============================] - 34s 85ms/step - loss: 1.0531 - accuracy: 0.6084 - val_loss: 1.1649 - val_accuracy: 0.5704\n","Epoch 20/320\n","406/406 [==============================] - 34s 85ms/step - loss: 1.0415 - accuracy: 0.6176 - val_loss: 1.0313 - val_accuracy: 0.6151\n","Epoch 21/320\n","406/406 [==============================] - 35s 85ms/step - loss: 1.0194 - accuracy: 0.6256 - val_loss: 1.0483 - val_accuracy: 0.6206\n","Epoch 22/320\n","406/406 [==============================] - 34s 84ms/step - loss: 1.0169 - accuracy: 0.6214 - val_loss: 1.0378 - val_accuracy: 0.6006\n","Epoch 23/320\n","406/406 [==============================] - 34s 85ms/step - loss: 1.0067 - accuracy: 0.6300 - val_loss: 1.0143 - val_accuracy: 0.6272\n","Epoch 24/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.9814 - accuracy: 0.6327 - val_loss: 1.0467 - val_accuracy: 0.6047\n","Epoch 25/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.9832 - accuracy: 0.6443 - val_loss: 0.9764 - val_accuracy: 0.6424\n","Epoch 26/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.9739 - accuracy: 0.6427 - val_loss: 1.0102 - val_accuracy: 0.6172\n","Epoch 27/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.9539 - accuracy: 0.6493 - val_loss: 1.0300 - val_accuracy: 0.6224\n","Epoch 28/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.9417 - accuracy: 0.6510 - val_loss: 1.0233 - val_accuracy: 0.6279\n","Epoch 29/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.9290 - accuracy: 0.6605 - val_loss: 0.9940 - val_accuracy: 0.6355\n","Epoch 30/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.9369 - accuracy: 0.6545 - val_loss: 1.0436 - val_accuracy: 0.6227\n","Epoch 31/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.9112 - accuracy: 0.6699 - val_loss: 0.9637 - val_accuracy: 0.6404\n","Epoch 32/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.9072 - accuracy: 0.6724 - val_loss: 0.9669 - val_accuracy: 0.6452\n","Epoch 33/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.9046 - accuracy: 0.6753 - val_loss: 0.9728 - val_accuracy: 0.6473\n","Epoch 34/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8846 - accuracy: 0.6780 - val_loss: 0.9713 - val_accuracy: 0.6449\n","Epoch 35/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8861 - accuracy: 0.6746 - val_loss: 0.9766 - val_accuracy: 0.6411\n","Epoch 36/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8858 - accuracy: 0.6782 - val_loss: 0.9759 - val_accuracy: 0.6438\n","Epoch 37/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8562 - accuracy: 0.6836 - val_loss: 0.9840 - val_accuracy: 0.6411\n","Epoch 38/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8467 - accuracy: 0.6922 - val_loss: 0.9283 - val_accuracy: 0.6653\n","Epoch 39/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8497 - accuracy: 0.6913 - val_loss: 1.0477 - val_accuracy: 0.6331\n","Epoch 40/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8493 - accuracy: 0.6917 - val_loss: 0.9401 - val_accuracy: 0.6587\n","Epoch 41/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8388 - accuracy: 0.7011 - val_loss: 0.9917 - val_accuracy: 0.6442\n","Epoch 42/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8334 - accuracy: 0.6966 - val_loss: 0.9417 - val_accuracy: 0.6618\n","Epoch 43/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.8359 - accuracy: 0.6961 - val_loss: 0.9409 - val_accuracy: 0.6611\n","Epoch 44/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8247 - accuracy: 0.7029 - val_loss: 0.9605 - val_accuracy: 0.6566\n","Epoch 45/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.8088 - accuracy: 0.7056 - val_loss: 1.0243 - val_accuracy: 0.6362\n","Epoch 46/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7915 - accuracy: 0.7120 - val_loss: 0.9893 - val_accuracy: 0.6417\n","Epoch 47/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7998 - accuracy: 0.7085 - val_loss: 0.9709 - val_accuracy: 0.6518\n","Epoch 48/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.7875 - accuracy: 0.7162 - val_loss: 0.9691 - val_accuracy: 0.6604\n","Epoch 49/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7778 - accuracy: 0.7224 - val_loss: 0.9497 - val_accuracy: 0.6518\n","Epoch 50/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.7791 - accuracy: 0.7212 - val_loss: 0.9333 - val_accuracy: 0.6698\n","Epoch 51/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7640 - accuracy: 0.7228 - val_loss: 0.9694 - val_accuracy: 0.6549\n","Epoch 52/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7496 - accuracy: 0.7332 - val_loss: 1.0000 - val_accuracy: 0.6494\n","Epoch 53/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7496 - accuracy: 0.7239 - val_loss: 0.9754 - val_accuracy: 0.6507\n","Epoch 54/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7405 - accuracy: 0.7298 - val_loss: 0.9562 - val_accuracy: 0.6687\n","Epoch 55/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7236 - accuracy: 0.7391 - val_loss: 0.9489 - val_accuracy: 0.6604\n","Epoch 56/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.7356 - accuracy: 0.7370 - val_loss: 0.9933 - val_accuracy: 0.6584\n","Epoch 57/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7102 - accuracy: 0.7490 - val_loss: 1.0011 - val_accuracy: 0.6608\n","Epoch 58/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7097 - accuracy: 0.7412 - val_loss: 0.9344 - val_accuracy: 0.6705\n","Epoch 59/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6988 - accuracy: 0.7461 - val_loss: 0.9489 - val_accuracy: 0.6760\n","Epoch 60/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.7119 - accuracy: 0.7387 - val_loss: 1.0093 - val_accuracy: 0.6708\n","Epoch 61/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.7081 - accuracy: 0.7479 - val_loss: 0.9498 - val_accuracy: 0.6705\n","Epoch 62/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6868 - accuracy: 0.7506 - val_loss: 0.9428 - val_accuracy: 0.6726\n","Epoch 63/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6864 - accuracy: 0.7548 - val_loss: 0.9881 - val_accuracy: 0.6708\n","Epoch 64/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6828 - accuracy: 0.7543 - val_loss: 0.9957 - val_accuracy: 0.6622\n","Epoch 65/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6862 - accuracy: 0.7554 - val_loss: 0.9668 - val_accuracy: 0.6719\n","Epoch 66/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6804 - accuracy: 0.7568 - val_loss: 0.9422 - val_accuracy: 0.6784\n","Epoch 67/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6627 - accuracy: 0.7627 - val_loss: 0.9997 - val_accuracy: 0.6584\n","Epoch 68/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.6669 - accuracy: 0.7616 - val_loss: 1.0154 - val_accuracy: 0.6660\n","Epoch 69/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.6357 - accuracy: 0.7717 - val_loss: 1.0008 - val_accuracy: 0.6722\n","Epoch 70/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6412 - accuracy: 0.7716 - val_loss: 1.0303 - val_accuracy: 0.6629\n","Epoch 71/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.6381 - accuracy: 0.7711 - val_loss: 0.9559 - val_accuracy: 0.6854\n","Epoch 72/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6363 - accuracy: 0.7733 - val_loss: 1.0181 - val_accuracy: 0.6822\n","Epoch 73/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6327 - accuracy: 0.7748 - val_loss: 0.9939 - val_accuracy: 0.6760\n","Epoch 74/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6320 - accuracy: 0.7694 - val_loss: 1.0338 - val_accuracy: 0.6805\n","Epoch 75/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.6182 - accuracy: 0.7787 - val_loss: 1.0530 - val_accuracy: 0.6726\n","Epoch 76/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.6186 - accuracy: 0.7784 - val_loss: 1.0778 - val_accuracy: 0.6805\n","Epoch 77/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5960 - accuracy: 0.7901 - val_loss: 1.0215 - val_accuracy: 0.6719\n","Epoch 78/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.6154 - accuracy: 0.7788 - val_loss: 1.0743 - val_accuracy: 0.6726\n","Epoch 79/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.6002 - accuracy: 0.7840 - val_loss: 1.0282 - val_accuracy: 0.6684\n","Epoch 80/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5893 - accuracy: 0.7877 - val_loss: 0.9994 - val_accuracy: 0.6722\n","Epoch 81/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.5985 - accuracy: 0.7835 - val_loss: 1.1282 - val_accuracy: 0.6570\n","Epoch 82/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5952 - accuracy: 0.7859 - val_loss: 1.0601 - val_accuracy: 0.6708\n","Epoch 83/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5829 - accuracy: 0.7907 - val_loss: 1.0699 - val_accuracy: 0.6705\n","Epoch 84/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5932 - accuracy: 0.7903 - val_loss: 1.0356 - val_accuracy: 0.6812\n","Epoch 85/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5721 - accuracy: 0.7961 - val_loss: 0.9990 - val_accuracy: 0.6850\n","Epoch 86/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5740 - accuracy: 0.7957 - val_loss: 1.0335 - val_accuracy: 0.6729\n","Epoch 87/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5713 - accuracy: 0.7957 - val_loss: 1.0408 - val_accuracy: 0.6788\n","Epoch 88/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5674 - accuracy: 0.7998 - val_loss: 1.1314 - val_accuracy: 0.6719\n","Epoch 89/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5618 - accuracy: 0.8000 - val_loss: 1.0830 - val_accuracy: 0.6791\n","Epoch 90/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5422 - accuracy: 0.8055 - val_loss: 1.2704 - val_accuracy: 0.6618\n","Epoch 91/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5433 - accuracy: 0.8052 - val_loss: 1.0907 - val_accuracy: 0.6701\n","Epoch 92/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.5437 - accuracy: 0.8064 - val_loss: 1.0749 - val_accuracy: 0.6816\n","Epoch 93/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5368 - accuracy: 0.8101 - val_loss: 1.0254 - val_accuracy: 0.6795\n","Epoch 94/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5348 - accuracy: 0.8101 - val_loss: 1.1725 - val_accuracy: 0.6618\n","Epoch 95/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5331 - accuracy: 0.8077 - val_loss: 1.0734 - val_accuracy: 0.6677\n","Epoch 96/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.5212 - accuracy: 0.8135 - val_loss: 1.1058 - val_accuracy: 0.6805\n","Epoch 97/320\n","406/406 [==============================] - 34s 84ms/step - loss: 0.5314 - accuracy: 0.8082 - val_loss: 1.1620 - val_accuracy: 0.6684\n","Epoch 98/320\n","406/406 [==============================] - 34s 85ms/step - loss: 0.5123 - accuracy: 0.8146 - val_loss: 1.0871 - val_accuracy: 0.6674\n","Epoch 99/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5149 - accuracy: 0.8176 - val_loss: 1.0672 - val_accuracy: 0.6822\n","Epoch 100/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5101 - accuracy: 0.8212 - val_loss: 1.0567 - val_accuracy: 0.6674\n","Epoch 101/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5108 - accuracy: 0.8169 - val_loss: 1.1324 - val_accuracy: 0.6757\n","Epoch 102/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.4972 - accuracy: 0.8215 - val_loss: 1.0635 - val_accuracy: 0.6774\n","Epoch 103/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5041 - accuracy: 0.8190 - val_loss: 1.1417 - val_accuracy: 0.6584\n","Epoch 104/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.5027 - accuracy: 0.8181 - val_loss: 1.1824 - val_accuracy: 0.6615\n","Epoch 105/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.5034 - accuracy: 0.8212 - val_loss: 1.1958 - val_accuracy: 0.6715\n","Epoch 106/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4805 - accuracy: 0.8270 - val_loss: 1.1240 - val_accuracy: 0.6850\n","Epoch 107/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4923 - accuracy: 0.8224 - val_loss: 1.2871 - val_accuracy: 0.6625\n","Epoch 108/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4719 - accuracy: 0.8305 - val_loss: 1.1727 - val_accuracy: 0.6587\n","Epoch 109/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.4798 - accuracy: 0.8312 - val_loss: 1.1249 - val_accuracy: 0.6795\n","Epoch 110/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4667 - accuracy: 0.8322 - val_loss: 1.1973 - val_accuracy: 0.6681\n","Epoch 111/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4784 - accuracy: 0.8292 - val_loss: 1.1978 - val_accuracy: 0.6559\n","Epoch 112/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4674 - accuracy: 0.8315 - val_loss: 1.1666 - val_accuracy: 0.6629\n","Epoch 113/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4610 - accuracy: 0.8325 - val_loss: 1.1593 - val_accuracy: 0.6798\n","Epoch 114/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4623 - accuracy: 0.8380 - val_loss: 1.1843 - val_accuracy: 0.6802\n","Epoch 115/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4587 - accuracy: 0.8348 - val_loss: 1.1487 - val_accuracy: 0.6760\n","Epoch 116/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4600 - accuracy: 0.8356 - val_loss: 1.1692 - val_accuracy: 0.6826\n","Epoch 117/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.4495 - accuracy: 0.8388 - val_loss: 1.1649 - val_accuracy: 0.6729\n","Epoch 118/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4387 - accuracy: 0.8439 - val_loss: 1.1331 - val_accuracy: 0.6826\n","Epoch 119/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4451 - accuracy: 0.8419 - val_loss: 1.1551 - val_accuracy: 0.6732\n","Epoch 120/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4540 - accuracy: 0.8401 - val_loss: 1.1842 - val_accuracy: 0.6788\n","Epoch 121/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4248 - accuracy: 0.8469 - val_loss: 1.1866 - val_accuracy: 0.6777\n","Epoch 122/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4320 - accuracy: 0.8466 - val_loss: 1.1797 - val_accuracy: 0.6781\n","Epoch 123/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4228 - accuracy: 0.8460 - val_loss: 1.2055 - val_accuracy: 0.6798\n","Epoch 124/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4262 - accuracy: 0.8467 - val_loss: 1.1571 - val_accuracy: 0.6847\n","Epoch 125/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4179 - accuracy: 0.8522 - val_loss: 1.2157 - val_accuracy: 0.6732\n","Epoch 126/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4083 - accuracy: 0.8562 - val_loss: 1.2147 - val_accuracy: 0.6760\n","Epoch 127/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4122 - accuracy: 0.8571 - val_loss: 1.2179 - val_accuracy: 0.6836\n","Epoch 128/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4084 - accuracy: 0.8551 - val_loss: 1.2423 - val_accuracy: 0.6777\n","Epoch 129/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4086 - accuracy: 0.8557 - val_loss: 1.2036 - val_accuracy: 0.6798\n","Epoch 130/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4109 - accuracy: 0.8552 - val_loss: 1.3126 - val_accuracy: 0.6608\n","Epoch 131/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4105 - accuracy: 0.8550 - val_loss: 1.2023 - val_accuracy: 0.6798\n","Epoch 132/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4041 - accuracy: 0.8580 - val_loss: 1.2186 - val_accuracy: 0.6726\n","Epoch 133/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3948 - accuracy: 0.8592 - val_loss: 1.1872 - val_accuracy: 0.6816\n","Epoch 134/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3946 - accuracy: 0.8598 - val_loss: 1.2498 - val_accuracy: 0.6732\n","Epoch 135/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.4004 - accuracy: 0.8584 - val_loss: 1.3170 - val_accuracy: 0.6746\n","Epoch 136/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3825 - accuracy: 0.8641 - val_loss: 1.2437 - val_accuracy: 0.6902\n","Epoch 137/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3919 - accuracy: 0.8646 - val_loss: 1.2503 - val_accuracy: 0.6895\n","Epoch 138/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3988 - accuracy: 0.8576 - val_loss: 1.2545 - val_accuracy: 0.6777\n","Epoch 139/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3957 - accuracy: 0.8575 - val_loss: 1.3353 - val_accuracy: 0.6729\n","Epoch 140/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3791 - accuracy: 0.8655 - val_loss: 1.2685 - val_accuracy: 0.6819\n","Epoch 141/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3684 - accuracy: 0.8699 - val_loss: 1.2925 - val_accuracy: 0.6767\n","Epoch 142/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3603 - accuracy: 0.8686 - val_loss: 1.2714 - val_accuracy: 0.6726\n","Epoch 143/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3717 - accuracy: 0.8653 - val_loss: 1.2372 - val_accuracy: 0.6850\n","Epoch 144/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3583 - accuracy: 0.8740 - val_loss: 1.2648 - val_accuracy: 0.6757\n","Epoch 145/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3628 - accuracy: 0.8742 - val_loss: 1.2680 - val_accuracy: 0.6784\n","Epoch 146/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3630 - accuracy: 0.8725 - val_loss: 1.2993 - val_accuracy: 0.6854\n","Epoch 147/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3622 - accuracy: 0.8711 - val_loss: 1.2715 - val_accuracy: 0.6864\n","Epoch 148/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3656 - accuracy: 0.8683 - val_loss: 1.3265 - val_accuracy: 0.6857\n","Epoch 149/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3565 - accuracy: 0.8713 - val_loss: 1.3130 - val_accuracy: 0.6829\n","Epoch 150/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3377 - accuracy: 0.8812 - val_loss: 1.2922 - val_accuracy: 0.6812\n","Epoch 151/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.3325 - accuracy: 0.8826 - val_loss: 1.4148 - val_accuracy: 0.6656\n","Epoch 152/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3632 - accuracy: 0.8723 - val_loss: 1.3406 - val_accuracy: 0.6736\n","Epoch 153/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3380 - accuracy: 0.8824 - val_loss: 1.2851 - val_accuracy: 0.6805\n","Epoch 154/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3457 - accuracy: 0.8780 - val_loss: 1.3289 - val_accuracy: 0.6764\n","Epoch 155/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3472 - accuracy: 0.8797 - val_loss: 1.2744 - val_accuracy: 0.6836\n","Epoch 156/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3310 - accuracy: 0.8813 - val_loss: 1.3197 - val_accuracy: 0.6864\n","Epoch 157/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3272 - accuracy: 0.8857 - val_loss: 1.2602 - val_accuracy: 0.6802\n","Epoch 158/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3424 - accuracy: 0.8798 - val_loss: 1.2843 - val_accuracy: 0.6829\n","Epoch 159/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3315 - accuracy: 0.8845 - val_loss: 1.2921 - val_accuracy: 0.6899\n","Epoch 160/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3223 - accuracy: 0.8860 - val_loss: 1.3652 - val_accuracy: 0.6822\n","Epoch 161/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3153 - accuracy: 0.8898 - val_loss: 1.2681 - val_accuracy: 0.6809\n","Epoch 162/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3250 - accuracy: 0.8830 - val_loss: 1.4725 - val_accuracy: 0.6521\n","Epoch 163/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3159 - accuracy: 0.8903 - val_loss: 1.2841 - val_accuracy: 0.6819\n","Epoch 164/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3166 - accuracy: 0.8890 - val_loss: 1.3801 - val_accuracy: 0.6822\n","Epoch 165/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3092 - accuracy: 0.8909 - val_loss: 1.4185 - val_accuracy: 0.6732\n","Epoch 166/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3207 - accuracy: 0.8888 - val_loss: 1.4381 - val_accuracy: 0.6715\n","Epoch 167/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3163 - accuracy: 0.8866 - val_loss: 1.4413 - val_accuracy: 0.6597\n","Epoch 168/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2966 - accuracy: 0.8954 - val_loss: 1.3942 - val_accuracy: 0.6874\n","Epoch 169/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3102 - accuracy: 0.8889 - val_loss: 1.2942 - val_accuracy: 0.6912\n","Epoch 170/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3048 - accuracy: 0.8924 - val_loss: 1.2846 - val_accuracy: 0.6816\n","Epoch 171/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2918 - accuracy: 0.8986 - val_loss: 1.3766 - val_accuracy: 0.6760\n","Epoch 172/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3034 - accuracy: 0.8954 - val_loss: 1.3445 - val_accuracy: 0.6798\n","Epoch 173/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.3100 - accuracy: 0.8936 - val_loss: 1.3337 - val_accuracy: 0.6836\n","Epoch 174/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2992 - accuracy: 0.8949 - val_loss: 1.3567 - val_accuracy: 0.6777\n","Epoch 175/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2926 - accuracy: 0.8964 - val_loss: 1.4448 - val_accuracy: 0.6722\n","Epoch 176/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2845 - accuracy: 0.9001 - val_loss: 1.4434 - val_accuracy: 0.6895\n","Epoch 177/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2850 - accuracy: 0.8985 - val_loss: 1.4026 - val_accuracy: 0.6753\n","Epoch 178/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2930 - accuracy: 0.8956 - val_loss: 1.3628 - val_accuracy: 0.6784\n","Epoch 179/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2817 - accuracy: 0.9010 - val_loss: 1.3437 - val_accuracy: 0.6809\n","Epoch 180/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2758 - accuracy: 0.9028 - val_loss: 1.3916 - val_accuracy: 0.6753\n","Epoch 181/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2939 - accuracy: 0.8963 - val_loss: 1.3566 - val_accuracy: 0.6874\n","Epoch 182/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2811 - accuracy: 0.8998 - val_loss: 1.3999 - val_accuracy: 0.6816\n","Epoch 183/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2804 - accuracy: 0.9032 - val_loss: 1.3450 - val_accuracy: 0.6822\n","Epoch 184/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2815 - accuracy: 0.8994 - val_loss: 1.4043 - val_accuracy: 0.6867\n","Epoch 185/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2753 - accuracy: 0.9046 - val_loss: 1.4363 - val_accuracy: 0.6732\n","Epoch 186/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2790 - accuracy: 0.9011 - val_loss: 1.4610 - val_accuracy: 0.6767\n","Epoch 187/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2735 - accuracy: 0.9029 - val_loss: 1.4050 - val_accuracy: 0.6798\n","Epoch 188/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2695 - accuracy: 0.9042 - val_loss: 1.4473 - val_accuracy: 0.6774\n","Epoch 189/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2800 - accuracy: 0.9012 - val_loss: 1.3438 - val_accuracy: 0.6843\n","Epoch 190/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2684 - accuracy: 0.9047 - val_loss: 1.4081 - val_accuracy: 0.6767\n","Epoch 191/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2622 - accuracy: 0.9054 - val_loss: 1.3520 - val_accuracy: 0.6864\n","Epoch 192/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2689 - accuracy: 0.9078 - val_loss: 1.3787 - val_accuracy: 0.6705\n","Epoch 193/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2558 - accuracy: 0.9100 - val_loss: 1.3791 - val_accuracy: 0.6843\n","Epoch 194/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2631 - accuracy: 0.9094 - val_loss: 1.4661 - val_accuracy: 0.6746\n","Epoch 195/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2489 - accuracy: 0.9133 - val_loss: 1.3749 - val_accuracy: 0.6843\n","Epoch 196/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2652 - accuracy: 0.9080 - val_loss: 1.3799 - val_accuracy: 0.6809\n","Epoch 197/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2528 - accuracy: 0.9119 - val_loss: 1.3681 - val_accuracy: 0.6919\n","Epoch 198/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2483 - accuracy: 0.9132 - val_loss: 1.3790 - val_accuracy: 0.6861\n","Epoch 199/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2535 - accuracy: 0.9100 - val_loss: 1.4480 - val_accuracy: 0.6819\n","Epoch 200/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2511 - accuracy: 0.9114 - val_loss: 1.4890 - val_accuracy: 0.6781\n","Epoch 201/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2574 - accuracy: 0.9101 - val_loss: 1.4631 - val_accuracy: 0.6857\n","Epoch 202/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2490 - accuracy: 0.9124 - val_loss: 1.4930 - val_accuracy: 0.6729\n","Epoch 203/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2399 - accuracy: 0.9161 - val_loss: 1.4170 - val_accuracy: 0.6822\n","Epoch 204/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2431 - accuracy: 0.9151 - val_loss: 1.3887 - val_accuracy: 0.6881\n","Epoch 205/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2419 - accuracy: 0.9140 - val_loss: 1.4984 - val_accuracy: 0.6777\n","Epoch 206/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2419 - accuracy: 0.9159 - val_loss: 1.5054 - val_accuracy: 0.6836\n","Epoch 207/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2383 - accuracy: 0.9168 - val_loss: 1.4091 - val_accuracy: 0.6940\n","Epoch 208/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2415 - accuracy: 0.9160 - val_loss: 1.4637 - val_accuracy: 0.6829\n","Epoch 209/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2333 - accuracy: 0.9187 - val_loss: 1.4139 - val_accuracy: 0.6909\n","Epoch 210/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2314 - accuracy: 0.9192 - val_loss: 1.4328 - val_accuracy: 0.6957\n","Epoch 211/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2315 - accuracy: 0.9189 - val_loss: 1.3978 - val_accuracy: 0.6885\n","Epoch 212/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2399 - accuracy: 0.9165 - val_loss: 1.4651 - val_accuracy: 0.6864\n","Epoch 213/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2294 - accuracy: 0.9205 - val_loss: 1.4613 - val_accuracy: 0.6926\n","Epoch 214/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2365 - accuracy: 0.9172 - val_loss: 1.5298 - val_accuracy: 0.6864\n","Epoch 215/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2326 - accuracy: 0.9177 - val_loss: 1.4619 - val_accuracy: 0.6812\n","Epoch 216/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2297 - accuracy: 0.9190 - val_loss: 1.4502 - val_accuracy: 0.6874\n","Epoch 217/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2179 - accuracy: 0.9257 - val_loss: 1.4386 - val_accuracy: 0.6784\n","Epoch 218/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2307 - accuracy: 0.9201 - val_loss: 1.4828 - val_accuracy: 0.6767\n","Epoch 219/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2148 - accuracy: 0.9286 - val_loss: 1.4398 - val_accuracy: 0.6812\n","Epoch 220/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2244 - accuracy: 0.9216 - val_loss: 1.4777 - val_accuracy: 0.6930\n","Epoch 221/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2324 - accuracy: 0.9205 - val_loss: 1.4563 - val_accuracy: 0.6923\n","Epoch 222/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2205 - accuracy: 0.9230 - val_loss: 1.4664 - val_accuracy: 0.6864\n","Epoch 223/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2268 - accuracy: 0.9210 - val_loss: 1.5002 - val_accuracy: 0.6798\n","Epoch 224/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2174 - accuracy: 0.9230 - val_loss: 1.4875 - val_accuracy: 0.6836\n","Epoch 225/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2132 - accuracy: 0.9254 - val_loss: 1.5060 - val_accuracy: 0.6805\n","Epoch 226/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2127 - accuracy: 0.9252 - val_loss: 1.5193 - val_accuracy: 0.6674\n","Epoch 227/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2208 - accuracy: 0.9226 - val_loss: 1.4840 - val_accuracy: 0.6729\n","Epoch 228/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2107 - accuracy: 0.9246 - val_loss: 1.4805 - val_accuracy: 0.6857\n","Epoch 229/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2179 - accuracy: 0.9242 - val_loss: 1.5179 - val_accuracy: 0.6788\n","Epoch 230/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2176 - accuracy: 0.9231 - val_loss: 1.5517 - val_accuracy: 0.6771\n","Epoch 231/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2098 - accuracy: 0.9269 - val_loss: 1.4947 - val_accuracy: 0.6736\n","Epoch 232/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2160 - accuracy: 0.9239 - val_loss: 1.5079 - val_accuracy: 0.6667\n","Epoch 233/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2093 - accuracy: 0.9260 - val_loss: 1.4834 - val_accuracy: 0.6819\n","Epoch 234/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2028 - accuracy: 0.9307 - val_loss: 1.5246 - val_accuracy: 0.6843\n","Epoch 235/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2071 - accuracy: 0.9263 - val_loss: 1.5626 - val_accuracy: 0.6736\n","Epoch 236/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2128 - accuracy: 0.9258 - val_loss: 1.5345 - val_accuracy: 0.6978\n","Epoch 237/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2030 - accuracy: 0.9286 - val_loss: 1.5092 - val_accuracy: 0.6836\n","Epoch 238/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2123 - accuracy: 0.9239 - val_loss: 1.4858 - val_accuracy: 0.6840\n","Epoch 239/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2066 - accuracy: 0.9302 - val_loss: 1.5425 - val_accuracy: 0.6826\n","Epoch 240/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2004 - accuracy: 0.9294 - val_loss: 1.6352 - val_accuracy: 0.6667\n","Epoch 241/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2115 - accuracy: 0.9260 - val_loss: 1.5155 - val_accuracy: 0.6878\n","Epoch 242/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2008 - accuracy: 0.9301 - val_loss: 1.5574 - val_accuracy: 0.6854\n","Epoch 243/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2006 - accuracy: 0.9302 - val_loss: 1.5283 - val_accuracy: 0.6850\n","Epoch 244/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2017 - accuracy: 0.9287 - val_loss: 1.5233 - val_accuracy: 0.6912\n","Epoch 245/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2008 - accuracy: 0.9291 - val_loss: 1.4732 - val_accuracy: 0.6892\n","Epoch 246/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1987 - accuracy: 0.9318 - val_loss: 1.5489 - val_accuracy: 0.6833\n","Epoch 247/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1959 - accuracy: 0.9309 - val_loss: 1.4941 - val_accuracy: 0.6881\n","Epoch 248/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2024 - accuracy: 0.9286 - val_loss: 1.5393 - val_accuracy: 0.6902\n","Epoch 249/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2007 - accuracy: 0.9330 - val_loss: 1.5445 - val_accuracy: 0.6926\n","Epoch 250/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1986 - accuracy: 0.9311 - val_loss: 1.4775 - val_accuracy: 0.6867\n","Epoch 251/320\n","406/406 [==============================] - 35s 85ms/step - loss: 0.2003 - accuracy: 0.9313 - val_loss: 1.5504 - val_accuracy: 0.6885\n","Epoch 252/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1866 - accuracy: 0.9347 - val_loss: 1.5759 - val_accuracy: 0.6822\n","Epoch 253/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1863 - accuracy: 0.9340 - val_loss: 1.5465 - val_accuracy: 0.6975\n","Epoch 254/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1954 - accuracy: 0.9322 - val_loss: 1.4954 - val_accuracy: 0.6864\n","Epoch 255/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1870 - accuracy: 0.9343 - val_loss: 1.5143 - val_accuracy: 0.6805\n","Epoch 256/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1893 - accuracy: 0.9344 - val_loss: 1.5306 - val_accuracy: 0.6729\n","Epoch 257/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.2059 - accuracy: 0.9277 - val_loss: 1.5820 - val_accuracy: 0.6888\n","Epoch 258/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1886 - accuracy: 0.9336 - val_loss: 1.5685 - val_accuracy: 0.6937\n","Epoch 259/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1920 - accuracy: 0.9347 - val_loss: 1.5916 - val_accuracy: 0.6822\n","Epoch 260/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1805 - accuracy: 0.9383 - val_loss: 1.5106 - val_accuracy: 0.6809\n","Epoch 261/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1880 - accuracy: 0.9359 - val_loss: 1.6752 - val_accuracy: 0.6701\n","Epoch 262/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1881 - accuracy: 0.9337 - val_loss: 1.6112 - val_accuracy: 0.6757\n","Epoch 263/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1872 - accuracy: 0.9329 - val_loss: 1.6538 - val_accuracy: 0.6774\n","Epoch 264/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1960 - accuracy: 0.9320 - val_loss: 1.5836 - val_accuracy: 0.6746\n","Epoch 265/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1750 - accuracy: 0.9397 - val_loss: 1.5460 - val_accuracy: 0.6795\n","Epoch 266/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1829 - accuracy: 0.9354 - val_loss: 1.6158 - val_accuracy: 0.6795\n","Epoch 267/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1713 - accuracy: 0.9416 - val_loss: 1.5756 - val_accuracy: 0.6802\n","Epoch 268/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1719 - accuracy: 0.9404 - val_loss: 1.5017 - val_accuracy: 0.6829\n","Epoch 269/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1803 - accuracy: 0.9376 - val_loss: 1.5786 - val_accuracy: 0.6795\n","Epoch 270/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1848 - accuracy: 0.9359 - val_loss: 1.5781 - val_accuracy: 0.6750\n","Epoch 271/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1759 - accuracy: 0.9368 - val_loss: 1.6110 - val_accuracy: 0.6712\n","Epoch 272/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1724 - accuracy: 0.9407 - val_loss: 1.5743 - val_accuracy: 0.6816\n","Epoch 273/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1731 - accuracy: 0.9397 - val_loss: 1.5995 - val_accuracy: 0.6771\n","Epoch 274/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1841 - accuracy: 0.9339 - val_loss: 1.5479 - val_accuracy: 0.6957\n","Epoch 275/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1755 - accuracy: 0.9376 - val_loss: 1.5895 - val_accuracy: 0.6912\n","Epoch 276/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1743 - accuracy: 0.9387 - val_loss: 1.5924 - val_accuracy: 0.6888\n","Epoch 277/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1633 - accuracy: 0.9426 - val_loss: 1.6066 - val_accuracy: 0.6812\n","Epoch 278/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1844 - accuracy: 0.9343 - val_loss: 1.5627 - val_accuracy: 0.6822\n","Epoch 279/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1695 - accuracy: 0.9391 - val_loss: 1.5903 - val_accuracy: 0.6816\n","Epoch 280/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1724 - accuracy: 0.9381 - val_loss: 1.6023 - val_accuracy: 0.6809\n","Epoch 281/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1776 - accuracy: 0.9387 - val_loss: 1.6074 - val_accuracy: 0.6847\n","Epoch 282/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1804 - accuracy: 0.9362 - val_loss: 1.5570 - val_accuracy: 0.6833\n","Epoch 283/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1717 - accuracy: 0.9403 - val_loss: 1.5922 - val_accuracy: 0.6795\n","Epoch 284/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1651 - accuracy: 0.9417 - val_loss: 1.6613 - val_accuracy: 0.6847\n","Epoch 285/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1700 - accuracy: 0.9395 - val_loss: 1.6009 - val_accuracy: 0.6757\n","Epoch 286/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1665 - accuracy: 0.9415 - val_loss: 1.5496 - val_accuracy: 0.6881\n","Epoch 287/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1702 - accuracy: 0.9420 - val_loss: 1.5268 - val_accuracy: 0.6722\n","Epoch 288/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1728 - accuracy: 0.9391 - val_loss: 1.6509 - val_accuracy: 0.6874\n","Epoch 289/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1683 - accuracy: 0.9421 - val_loss: 1.5983 - val_accuracy: 0.6850\n","Epoch 290/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1658 - accuracy: 0.9406 - val_loss: 1.7493 - val_accuracy: 0.6750\n","Epoch 291/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1615 - accuracy: 0.9444 - val_loss: 1.6228 - val_accuracy: 0.6816\n","Epoch 292/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1709 - accuracy: 0.9413 - val_loss: 1.7285 - val_accuracy: 0.6795\n","Epoch 293/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1605 - accuracy: 0.9421 - val_loss: 1.6574 - val_accuracy: 0.6867\n","Epoch 294/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1590 - accuracy: 0.9454 - val_loss: 1.6374 - val_accuracy: 0.6764\n","Epoch 295/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1603 - accuracy: 0.9426 - val_loss: 1.6845 - val_accuracy: 0.6674\n","Epoch 296/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1649 - accuracy: 0.9412 - val_loss: 1.6189 - val_accuracy: 0.6867\n","Epoch 297/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1548 - accuracy: 0.9452 - val_loss: 1.5734 - val_accuracy: 0.6864\n","Epoch 298/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1568 - accuracy: 0.9453 - val_loss: 1.6615 - val_accuracy: 0.6670\n","Epoch 299/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1586 - accuracy: 0.9435 - val_loss: 1.6173 - val_accuracy: 0.6774\n","Epoch 300/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1505 - accuracy: 0.9479 - val_loss: 1.7441 - val_accuracy: 0.6767\n","Epoch 301/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1628 - accuracy: 0.9440 - val_loss: 1.6740 - val_accuracy: 0.6885\n","Epoch 302/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1557 - accuracy: 0.9450 - val_loss: 1.6265 - val_accuracy: 0.6867\n","Epoch 303/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1616 - accuracy: 0.9431 - val_loss: 1.5783 - val_accuracy: 0.6871\n","Epoch 304/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1519 - accuracy: 0.9465 - val_loss: 1.7177 - val_accuracy: 0.6822\n","Epoch 305/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1562 - accuracy: 0.9440 - val_loss: 1.6611 - val_accuracy: 0.6809\n","Epoch 306/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1553 - accuracy: 0.9466 - val_loss: 1.6723 - val_accuracy: 0.6753\n","Epoch 307/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1557 - accuracy: 0.9417 - val_loss: 1.6401 - val_accuracy: 0.6746\n","Epoch 308/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1613 - accuracy: 0.9416 - val_loss: 1.5840 - val_accuracy: 0.6802\n","Epoch 309/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1519 - accuracy: 0.9476 - val_loss: 1.6607 - val_accuracy: 0.6864\n","Epoch 310/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1557 - accuracy: 0.9453 - val_loss: 1.7022 - val_accuracy: 0.6836\n","Epoch 311/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1394 - accuracy: 0.9519 - val_loss: 1.6626 - val_accuracy: 0.6771\n","Epoch 312/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1481 - accuracy: 0.9471 - val_loss: 1.7201 - val_accuracy: 0.6809\n","Epoch 313/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1498 - accuracy: 0.9469 - val_loss: 1.7576 - val_accuracy: 0.6719\n","Epoch 314/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1484 - accuracy: 0.9503 - val_loss: 1.7078 - val_accuracy: 0.6895\n","Epoch 315/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1507 - accuracy: 0.9475 - val_loss: 1.5900 - val_accuracy: 0.6867\n","Epoch 316/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1472 - accuracy: 0.9465 - val_loss: 1.5836 - val_accuracy: 0.6912\n","Epoch 317/320\n","406/406 [==============================] - 35s 87ms/step - loss: 0.1524 - accuracy: 0.9480 - val_loss: 1.6460 - val_accuracy: 0.6687\n","Epoch 318/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1466 - accuracy: 0.9458 - val_loss: 1.7264 - val_accuracy: 0.6750\n","Epoch 319/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1492 - accuracy: 0.9466 - val_loss: 1.6442 - val_accuracy: 0.6871\n","Epoch 320/320\n","406/406 [==============================] - 35s 86ms/step - loss: 0.1525 - accuracy: 0.9452 - val_loss: 1.6337 - val_accuracy: 0.6788\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FQH28fPaPVoa"},"source":["## vii. Make predictions and export as prediction_team8.csv file"]},{"cell_type":"code","metadata":{"id":"EBY_0S-qeA3E"},"source":["y_pred = model.predict(X_)\n","y_pred = np.argmax(y_pred, axis=1)\n","header = ['Id', 'Category']\n","f = open('/content/drive/MyDrive/ML_project/result/prediction_team8.csv', 'w', encoding='UTF8', newline='')\n","writer = csv.writer(f)\n","writer.writerow(header)\n","for i in range(y_pred.shape[0]):\n","    row = [i, y_pred[i]]\n","    writer.writerow(row)\n","f.close()"],"execution_count":null,"outputs":[]}]}